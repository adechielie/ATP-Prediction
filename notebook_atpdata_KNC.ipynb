{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WKdbmejgzg8P",
        "outputId": "d5d4daef-21d3-46a4-ebf3-4e0320b1b3b3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "dO4S_27TbJXT"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "#Lecture des fichiers github de résultats entre 2005 et 2022\n",
        "\n",
        "\n",
        "atp_matches_2005 = pd.read_csv('atp_matches_2005.csv')\n",
        "atp_matches_2006 = pd.read_csv('atp_matches_2006.csv')\n",
        "atp_matches_2007 = pd.read_csv('atp_matches_2007.csv')\n",
        "atp_matches_2008 = pd.read_csv('atp_matches_2008.csv')\n",
        "atp_matches_2009 = pd.read_csv('atp_matches_2009.csv')\n",
        "atp_matches_2010 = pd.read_csv('atp_matches_2010.csv')\n",
        "atp_matches_2011 = pd.read_csv('atp_matches_2011.csv')\n",
        "atp_matches_2012 = pd.read_csv('atp_matches_2012.csv')\n",
        "atp_matches_2013 = pd.read_csv('atp_matches_2013.csv')\n",
        "atp_matches_2014 = pd.read_csv('atp_matches_2014.csv')\n",
        "atp_matches_2015 = pd.read_csv('atp_matches_2015.csv')\n",
        "atp_matches_2016 = pd.read_csv('atp_matches_2016.csv')\n",
        "atp_matches_2017 = pd.read_csv('atp_matches_2017.csv')\n",
        "atp_matches_2018 = pd.read_csv('atp_matches_2018.csv')\n",
        "atp_matches_2019 = pd.read_csv('atp_matches_2019.csv')\n",
        "atp_matches_2020 = pd.read_csv('atp_matches_2020.csv')\n",
        "\n",
        "\n",
        "# Concaténation des tableaux en un seul dataframe\n",
        "\n",
        "atpdata_github = pd.concat([atp_matches_2009, atp_matches_2010, atp_matches_2011, atp_matches_2012,\n",
        "                            atp_matches_2013, atp_matches_2014, atp_matches_2015, atp_matches_2016,\n",
        "                            atp_matches_2017, atp_matches_2018, atp_matches_2019, atp_matches_2020\n",
        "                            ], join = 'outer',ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "# Suppression des colonnes non nécessaires\n",
        "atpdata_github.drop(columns=['draw_size','winner_seed','winner_entry','loser_seed','loser_entry'], inplace=True)\n",
        "atpdata_github.rename(columns={'tourney_date':'Date'}, inplace=True)\n",
        "atpdata_github['Date'] = pd.to_datetime(atpdata_github['Date'], format='%Y%m%d')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S3f9UUFdYmuU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#Export des données de température pour Paris\n",
        "\n",
        "temp_paris09 = pd.read_csv('export-paris2009.csv', skiprows=3)\n",
        "temp_paris10 = pd.read_csv('export-paris2010.csv', skiprows=3)\n",
        "temp_paris11 = pd.read_csv('export-paris2011.csv', skiprows=3)\n",
        "temp_paris12 = pd.read_csv('export-paris2012.csv', skiprows=3)\n",
        "temp_paris13 = pd.read_csv('export-paris2013.csv', skiprows=3)\n",
        "temp_paris14 = pd.read_csv('export-paris2014.csv', skiprows=3)\n",
        "temp_paris15 = pd.read_csv('export-paris2015.csv', skiprows=3)\n",
        "temp_paris16 = pd.read_csv('export-paris2016.csv', skiprows=3)\n",
        "temp_paris17 = pd.read_csv('export-paris2017.csv', skiprows=3)\n",
        "temp_paris18 = pd.read_csv('export-paris2018.csv', skiprows=3)\n",
        "temp_paris19 = pd.read_csv('export-paris2019.csv', skiprows=3)\n",
        "temp_paris20 = pd.read_csv('export-paris2020.csv', skiprows=3)\n",
        "temp_paris21 = pd.read_csv('export-paris2021.csv', skiprows=3)\n",
        "temp_paris22 = pd.read_csv('export-paris2022.csv', skiprows=3)\n",
        "\n",
        "#Export des données de température pour Londres\n",
        "\n",
        "temp_londres09 = pd.read_csv('export-londres2009.csv', skiprows=3)\n",
        "temp_londres10 = pd.read_csv('export-londres2010.csv', skiprows=3)\n",
        "temp_londres11 = pd.read_csv('export-londres2011.csv', skiprows=3)\n",
        "temp_londres12 = pd.read_csv('export-londres2012.csv', skiprows=3)\n",
        "temp_londres13 = pd.read_csv('export-londres2013.csv', skiprows=3)\n",
        "temp_londres14 = pd.read_csv('export-londres2014.csv', skiprows=3)\n",
        "temp_londres15 = pd.read_csv('export-londres2015.csv', skiprows=3)\n",
        "temp_londres16 = pd.read_csv('export-londres2016.csv', skiprows=3)\n",
        "temp_londres17 = pd.read_csv('export-londres2017.csv', skiprows=3)\n",
        "temp_londres18 = pd.read_csv('export-londres2018.csv', skiprows=3)\n",
        "temp_londres19 = pd.read_csv('export-londres2019.csv', skiprows=3)\n",
        "temp_londres20 = pd.read_csv('export-londres2020.csv', skiprows=3)\n",
        "temp_londres21 = pd.read_csv('export-londres2021.csv', skiprows=3)\n",
        "temp_londres22 = pd.read_csv('export-londres2022.csv', skiprows=3)\n",
        "\n",
        "#Export des données de température pour New-york\n",
        "\n",
        "temp_newyork09 = pd.read_csv('export-new-york2009.csv', skiprows=3)\n",
        "temp_newyork10 = pd.read_csv('export-new-york2010.csv', skiprows=3)\n",
        "temp_newyork11 = pd.read_csv('export-new-york2011.csv', skiprows=3)\n",
        "temp_newyork12 = pd.read_csv('export-new-york2012.csv', skiprows=3)\n",
        "temp_newyork13 = pd.read_csv('export-new-york2013.csv', skiprows=3)\n",
        "temp_newyork14 = pd.read_csv('export-new-york2014.csv', skiprows=3)\n",
        "temp_newyork15 = pd.read_csv('export-new-york2015.csv', skiprows=3)\n",
        "temp_newyork16 = pd.read_csv('export-new-york2016.csv', skiprows=3)\n",
        "temp_newyork17 = pd.read_csv('export-new-york2017.csv', skiprows=3)\n",
        "temp_newyork18 = pd.read_csv('export-new-york2018.csv', skiprows=3)\n",
        "temp_newyork19 = pd.read_csv('export-new-york2019.csv', skiprows=3)\n",
        "temp_newyork20 = pd.read_csv('export-new-york2020.csv', skiprows=3)\n",
        "temp_newyork21 = pd.read_csv('export-new-york2021.csv', skiprows=3)\n",
        "temp_newyork22 = pd.read_csv('export-new-york2022.csv', skiprows=3)\n",
        "\n",
        "#Export des données de température pour Melbourne\n",
        "\n",
        "temp_melbourne09 = pd.read_csv('export-melbourne2009.csv', skiprows=3)\n",
        "temp_melbourne10 = pd.read_csv('export-melbourne2010.csv', skiprows=3)\n",
        "temp_melbourne11 = pd.read_csv('export-melbourne2011.csv', skiprows=3)\n",
        "temp_melbourne12 = pd.read_csv('export-melbourne2012.csv', skiprows=3)\n",
        "temp_melbourne13 = pd.read_csv('export-melbourne2013.csv', skiprows=3)\n",
        "temp_melbourne14 = pd.read_csv('export-melbourne2014.csv', skiprows=3)\n",
        "temp_melbourne15 = pd.read_csv('export-melbourne2015.csv', skiprows=3)\n",
        "temp_melbourne16 = pd.read_csv('export-melbourne2016.csv', skiprows=3)\n",
        "temp_melbourne17 = pd.read_csv('export-melbourne2017.csv', skiprows=3)\n",
        "temp_melbourne18 = pd.read_csv('export-melbourne2018.csv', skiprows=3)\n",
        "temp_melbourne19 = pd.read_csv('export-melbourne2019.csv', skiprows=3)\n",
        "temp_melbourne20 = pd.read_csv('export-melbourne2020.csv', skiprows=3)\n",
        "temp_melbourne21 = pd.read_csv('export-melbourne2021.csv', skiprows=3)\n",
        "temp_melbourne22 = pd.read_csv('export-melbourne2022.csv', skiprows=3)\n",
        "\n",
        "# Fusion des dataframes de données météo de Sydney entre 2009 et 2022\n",
        "\n",
        "list_temp_melbourne =[temp_melbourne09, temp_melbourne10, temp_melbourne11, temp_melbourne12, temp_melbourne13,\n",
        "                        temp_melbourne14, temp_melbourne15, temp_melbourne16, temp_melbourne17, temp_melbourne18,\n",
        "                        temp_melbourne19, temp_melbourne20]\n",
        "temp_melbourne = pd.concat(list_temp_melbourne)\n",
        "\n",
        "# Fusion des dataframes de données météo de Paris entre 2009 et 2022\n",
        "\n",
        "list_temp_paris =[temp_paris09, temp_paris10, temp_paris11, temp_paris12, temp_paris13,\n",
        "                        temp_paris14, temp_paris15, temp_paris16, temp_paris17, temp_paris18,\n",
        "                        temp_paris19, temp_paris20]\n",
        "\n",
        "temp_paris = pd.concat(list_temp_paris)\n",
        "\n",
        "# Fusion des dataframes de données météo de Londres entre 2009 et 2022\n",
        "\n",
        "list_temp_londres =[temp_londres09, temp_londres10, temp_londres11, temp_londres12, temp_londres13,\n",
        "                        temp_londres14, temp_londres15, temp_londres16, temp_londres17, temp_londres18,\n",
        "                        temp_londres19, temp_londres20]\n",
        "\n",
        "\n",
        "temp_londres = pd.concat(list_temp_londres)\n",
        "\n",
        "# Fusion des dataframes de données météo de New-York entre 2009 et 2022\n",
        "\n",
        "list_temp_newyork =[temp_newyork09, temp_newyork10, temp_newyork11, temp_newyork12, temp_newyork13,\n",
        "                        temp_newyork14, temp_newyork15, temp_newyork16, temp_newyork17, temp_newyork18,\n",
        "                        temp_newyork19, temp_newyork20]\n",
        "\n",
        "temp_newyork = pd.concat(list_temp_newyork)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "SpjanA4JZEHk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00aa4796-9a47-4772-cdcf-e6433e38f814"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-db31dbec6450>:150: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  atpdatafinal.drop(columns={'tourney_id','loser_id','winner_id','match_num','score'},inplace = True)\n",
            "<ipython-input-31-db31dbec6450>:192: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  atpdatafinal.rename(columns=columns_to_rename, inplace=True)\n",
            "<ipython-input-31-db31dbec6450>:193: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  atpdatafinal.rename(columns=columns_to_rename2, inplace=True)\n",
            "<ipython-input-31-db31dbec6450>:197: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  atpdatafinal['result'] = atpdatafinal['P1']\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
            "<ipython-input-31-db31dbec6450>:252: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['tourney_name', 'surface', 'tourney_level', 'P1', 'P1_hand', 'P1_ioc',\n",
            "       'P2', 'P2_hand', 'P2_ioc', 'round', 'result'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "# Ajout d'une colonne 'Location' avec comme valeur 'Paris' dans le dataframe temp_paris\n",
        "temp_paris = temp_paris.assign(tourney_name='Roland Garros')\n",
        "\n",
        "# Ajout d'une colonne 'Location' avec comme valeur 'London' dans le dataframe temp_paris\n",
        "temp_londres = temp_londres.assign(tourney_name='Wimbledon')\n",
        "\n",
        "# Ajout d'une colonne 'Location' avec comme valeur 'New York' dans le dataframe temp_newyork\n",
        "temp_newyork = temp_newyork.assign(tourney_name='US Open')\n",
        "\n",
        "# Ajout d'une colonne 'Location' avec comme valeur 'Melbourne' dans le dataframe temp_sydney\n",
        "temp_melbourne = temp_melbourne.assign(tourney_name='Australian Open')\n",
        "\n",
        "#Renommer la colonne DATE en Date\n",
        "temp_melbourne = temp_melbourne.rename(columns={'DATE': 'Date'})\n",
        "temp_melbourne['Date'] = pd.to_datetime(temp_melbourne['Date'], format='%Y-%m-%d')\n",
        "\n",
        "temp_paris = temp_paris.rename(columns={'DATE': 'Date'})\n",
        "temp_paris['Date'] = pd.to_datetime(temp_paris['Date'], format='%Y-%m-%d')\n",
        "\n",
        "temp_newyork = temp_newyork.rename(columns={'DATE': 'Date'})\n",
        "temp_newyork['Date'] = pd.to_datetime(temp_newyork['Date'], format='%Y-%m-%d')\n",
        "\n",
        "temp_londres = temp_londres.rename(columns={'DATE': 'Date'})\n",
        "temp_londres['Date'] = pd.to_datetime(temp_londres['Date'], format='%Y-%m-%d')\n",
        "\n",
        "\n",
        "# Suppression des colonnes non utiles\n",
        "\n",
        "temp_melbourne = temp_melbourne.drop(columns=['HEATINDEX_MAX_C','PRECIP_TOTAL_DAY_MM','MIN_TEMPERATURE_C','TEMPERATURE_MORNING_C','TEMPERATURE_NOON_C','TEMPERATURE_EVENING_C',\n",
        "                                        'VISIBILITY_AVG_KM','PRESSURE_MAX_MB','CLOUDCOVER_AVG_PERCENT',\n",
        "                                        'DEWPOINT_MAX_C','WINDTEMP_MAX_C','WEATHER_CODE_MORNING',\n",
        "                                        'WEATHER_CODE_NOON','WEATHER_CODE_EVENING','TOTAL_SNOW_MM',\n",
        "                                        'UV_INDEX','SUNHOUR','OPINION', 'SUNSET', 'SUNRISE', 'TEMPERATURE_NIGHT_C','WINDSPEED_MAX_KMH'])\n",
        "\n",
        "temp_paris = temp_paris.drop(columns=['HEATINDEX_MAX_C','PRECIP_TOTAL_DAY_MM','MIN_TEMPERATURE_C','TEMPERATURE_MORNING_C','TEMPERATURE_NOON_C','TEMPERATURE_EVENING_C',\n",
        "                                        'VISIBILITY_AVG_KM','PRESSURE_MAX_MB','CLOUDCOVER_AVG_PERCENT',\n",
        "                                        'DEWPOINT_MAX_C','WINDTEMP_MAX_C','WEATHER_CODE_MORNING',\n",
        "                                        'WEATHER_CODE_NOON','WEATHER_CODE_EVENING','TOTAL_SNOW_MM',\n",
        "                                        'UV_INDEX','SUNHOUR','OPINION', 'SUNSET', 'SUNRISE', 'TEMPERATURE_NIGHT_C','WINDSPEED_MAX_KMH'])\n",
        "\n",
        "temp_londres = temp_londres.drop(columns=['HEATINDEX_MAX_C','PRECIP_TOTAL_DAY_MM','MIN_TEMPERATURE_C','TEMPERATURE_MORNING_C','TEMPERATURE_NOON_C','TEMPERATURE_EVENING_C',\n",
        "                                        'VISIBILITY_AVG_KM','PRESSURE_MAX_MB','CLOUDCOVER_AVG_PERCENT',\n",
        "                                        'DEWPOINT_MAX_C','WINDTEMP_MAX_C','WEATHER_CODE_MORNING',\n",
        "                                        'WEATHER_CODE_NOON','WEATHER_CODE_EVENING','TOTAL_SNOW_MM',\n",
        "                                        'UV_INDEX','SUNHOUR','OPINION', 'SUNSET', 'SUNRISE', 'TEMPERATURE_NIGHT_C','WINDSPEED_MAX_KMH'])\n",
        "\n",
        "temp_newyork = temp_newyork.drop(columns=['HEATINDEX_MAX_C','PRECIP_TOTAL_DAY_MM','MIN_TEMPERATURE_C','TEMPERATURE_MORNING_C','TEMPERATURE_NOON_C','TEMPERATURE_EVENING_C',\n",
        "                                        'VISIBILITY_AVG_KM','PRESSURE_MAX_MB','CLOUDCOVER_AVG_PERCENT',\n",
        "                                        'DEWPOINT_MAX_C','WINDTEMP_MAX_C','WEATHER_CODE_MORNING',\n",
        "                                        'WEATHER_CODE_NOON','WEATHER_CODE_EVENING','TOTAL_SNOW_MM',\n",
        "                                        'UV_INDEX','SUNHOUR','OPINION', 'SUNSET', 'SUNRISE', 'TEMPERATURE_NIGHT_C','WINDSPEED_MAX_KMH'])\n",
        "\n",
        "# Fusionner les DataFrames en utilisant une jointure gauche\n",
        "atpdatanew = atpdata_github.merge(temp_paris, on=['Date', 'tourney_name'], how='left')\n",
        "atpdatanew1 = atpdatanew.merge(temp_londres, on=['Date', 'tourney_name',], how='left')\n",
        "\n",
        "# Remplacer les valeurs de 'MAX_TEMPERATURE_C_x' par les valeurs de 'MAX_TEMPERATURE_C_y' pour les lignes avec Location == 'Londres'\n",
        "# Puis faire de même pour 'HUMIDITY_MAX_PERCENT_x'\n",
        "Londres_rows = atpdatanew1[atpdatanew1['tourney_name'] == 'Wimbledon']\n",
        "atpdatanew1.loc[Londres_rows.index, 'MAX_TEMPERATURE_C_x'] = Londres_rows['MAX_TEMPERATURE_C_y']\n",
        "atpdatanew1.loc[Londres_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = Londres_rows['HUMIDITY_MAX_PERCENT_y']\n",
        "atpdatanew1.drop(columns={'MAX_TEMPERATURE_C_y','HUMIDITY_MAX_PERCENT_y'},inplace = True)\n",
        "\n",
        "#\n",
        "atpdatanew2 = atpdatanew1.merge(temp_newyork, on=['Date', 'tourney_name'], how='left')\n",
        "newyork_rows = atpdatanew2[atpdatanew2['tourney_name'] == 'US Open']\n",
        "atpdatanew2.loc[newyork_rows.index, 'MAX_TEMPERATURE_C_x'] = newyork_rows['MAX_TEMPERATURE_C']\n",
        "atpdatanew2.loc[newyork_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = newyork_rows['HUMIDITY_MAX_PERCENT']\n",
        "atpdatanew2.drop(columns={'MAX_TEMPERATURE_C','HUMIDITY_MAX_PERCENT'},inplace = True)\n",
        "\n",
        "#\n",
        "atpdatanew3 = atpdatanew2.merge(temp_melbourne, on=['Date', 'tourney_name'], how='left')\n",
        "melbourne_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Australian Open']\n",
        "atpdatanew3.loc[melbourne_rows.index, 'MAX_TEMPERATURE_C_x'] = melbourne_rows['MAX_TEMPERATURE_C']\n",
        "atpdatanew3.loc[melbourne_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = melbourne_rows['HUMIDITY_MAX_PERCENT']\n",
        "\n",
        "atpdatanew3.drop(columns={'MAX_TEMPERATURE_C','HUMIDITY_MAX_PERCENT'},inplace = True)\n",
        "#\n",
        "madrid_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Madrid Masters']\n",
        "atpdatanew3.loc[madrid_rows.index, 'MAX_TEMPERATURE_C_x'] = 18\n",
        "atpdatanew3.loc[madrid_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 80\n",
        "\n",
        "#\n",
        "rome_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Rome Masters']\n",
        "atpdatanew3.loc[rome_rows.index, 'MAX_TEMPERATURE_C_x'] = 24\n",
        "atpdatanew3.loc[rome_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 60\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Paris Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 13\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 69\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Miami Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 25\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 76\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Canada Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 26\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 66\n",
        "\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Cincinnati Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 24\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 65\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Indian Wells Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 27\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 33\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Monte Carlo Masters']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 16\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 75\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Barcelona']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 13\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 75\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Washington']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 27\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 66\n",
        "\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == \"Queen's Club\"]\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 16\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 68\n",
        "\n",
        "\n",
        "#\n",
        "x_rows = atpdatanew3[atpdatanew3['tourney_name'] == 'Halle']\n",
        "atpdatanew3.loc[x_rows.index, 'MAX_TEMPERATURE_C_x'] = 18\n",
        "atpdatanew3.loc[x_rows.index, 'HUMIDITY_MAX_PERCENT_x'] = 65\n",
        "\n",
        "\n",
        "# Liste des tournois retenus\n",
        "tournois_autorises = ['Roland Garros','Wimbledon','US Open','Australian Open','Halle', 'Queen\\'s Club', 'Washington', 'Barcelona', 'Monte Carlo Masters', 'Indian Wells Masters', 'Cincinnati Masters', 'Canada Masters', 'Miami Masters', 'Paris Masters', 'Rome Masters', 'Madrid Masters']\n",
        "\n",
        "# Filtrer le DataFrame pour inclure uniquement les tournois retenus\n",
        "atpdatanew3 = atpdatanew3[atpdatanew3['tourney_name'].isin(tournois_autorises)]\n",
        "\n",
        "atpdatafinal = atpdatanew3.dropna()\n",
        "\n",
        "atpdatafinal.drop(columns={'tourney_id','loser_id','winner_id','match_num','score'},inplace = True)\n",
        "\n",
        "\n",
        "# Liste des colonnes vainqueur à renommer\n",
        "columns_to_rename = {\n",
        "    'winner_name': 'P1',\n",
        "    'winner_hand': 'P1_hand',\n",
        "    'winner_ht': 'P1_ht',\n",
        "    'winner_ioc': 'P1_ioc',\n",
        "    'winner_age': 'P1_age',\n",
        "    'w_ace' : 'P1_ace',\n",
        "    'w_df' : 'P1_df',\n",
        "    'w_1stIn' : 'P1_1stIn',\n",
        "    'w_1stWon' : 'P1_1stWon',\n",
        "    'w_2ndWon' : 'P1_2ndWon',\n",
        "      'w_SvGms' : 'P1_SvGms',\n",
        "     'w_bpSaved' : 'P1_bpSaved',\n",
        "     'w_bpFaced' : 'P1_bpFaced',\n",
        "    'winner_rank' :'P1_rank',\n",
        "    'winner_rank_points' : 'P1_rank_pts',\n",
        "    'w_svpt' : 'P1_svpt'\n",
        "}\n",
        "\n",
        "# Liste des colonnes loser à renommer\n",
        "columns_to_rename2 = {'loser_name': 'P2',\n",
        "    'loser_hand': 'P2_hand',\n",
        "    'loser_ht': 'P2_ht',\n",
        "    'loser_ioc': 'P2_ioc',\n",
        "    'loser_age': 'P2_age',\n",
        "    'l_ace' : 'P2_ace',\n",
        "    'l_df' : 'P2_df',\n",
        "    'l_1stIn' : 'P2_1stIn',\n",
        "    'l_1stWon' : 'P2_1stWon',\n",
        "    'l_2ndWon' : 'P2_2ndWon',\n",
        "      'l_SvGms' : 'P2_SvGms',\n",
        "     'l_bpSaved' : 'P2_bpSaved',\n",
        "     'l_bpFaced' : 'P2_bpFaced',\n",
        "    'loser_rank' :'P2_rank',\n",
        "    'loser_rank_points' : 'P2_rank_pts',\n",
        "    'l_svpt' : 'P2_svpt'}\n",
        "\n",
        "# Renommer les colonnes\n",
        "atpdatafinal.rename(columns=columns_to_rename, inplace=True)\n",
        "atpdatafinal.rename(columns=columns_to_rename2, inplace=True)\n",
        "\n",
        "\n",
        "# Créer une nouvelle colonne result\n",
        "atpdatafinal['result'] = atpdatafinal['P1']\n",
        "\n",
        "\n",
        "# Liste des colonnes correspondantes pour P1\n",
        "colonnes_P1 = ['P1', 'P1_hand', 'P1_ht', 'P1_ioc', 'P1_age', 'P1_ace', 'P1_SvGms', 'P1_bpSaved', 'P1_bpFaced',\n",
        "               'P1_rank', 'P1_rank_pts', 'P1_df', 'P1_svpt',  'P1_1stIn', 'P1_1stWon', 'P1_2ndWon']\n",
        "\n",
        "# Liste des colonnes correspondantes pour P2\n",
        "colonnes_P2 = ['P2','P2_hand','P2_ht','P2_ioc','P2_age','P2_ace', 'P2_SvGms', 'P2_bpSaved','P2_bpFaced','P2_rank', 'P2_rank_pts', 'P2_df', 'P2_svpt' , 'P2_1stIn', 'P2_1stWon', 'P2_2ndWon' ]\n",
        "\n",
        "# Créer une copie du DataFrame\n",
        "copie_atpdatafinal = atpdatafinal.copy()\n",
        "\n",
        "# Inverser les valeurs entre colonnes_P1 et colonnes_P2 dans la copie\n",
        "for colonnes_P1, colonnes_P2 in zip(colonnes_P1, colonnes_P2):\n",
        "    # Échanger les valeurs entre P1 et P2\n",
        "    copie_atpdatafinal[colonnes_P1], copie_atpdatafinal[colonnes_P2] = (\n",
        "        copie_atpdatafinal[colonnes_P2].values,\n",
        "        copie_atpdatafinal[colonnes_P1].values\n",
        "    )\n",
        "\n",
        "\n",
        "# Concaténer les deux DataFrames\n",
        "merged_atpdatafinal = pd.concat([atpdatafinal, copie_atpdatafinal])\n",
        "\n",
        "# Trier par la date dans l'ordre croissant\n",
        "merged_atpdatafinal = merged_atpdatafinal.sort_values(by='Date', ascending=True)\n",
        "\n",
        "\n",
        "# Remplacez les valeurs de 'result' par 1 si elles sont égales à 'P1'\n",
        "merged_atpdatafinal['result'] = np.where(merged_atpdatafinal['result'] == merged_atpdatafinal['P1'], 1, merged_atpdatafinal['result'])\n",
        "\n",
        "# Remplacez les valeurs de 'result' par -1 si elles sont égales à 'P2'\n",
        "merged_atpdatafinal['result'] = np.where(merged_atpdatafinal['result'] == merged_atpdatafinal['P2'], -1, merged_atpdatafinal['result'])\n",
        "\n",
        "merged_atpdatafinal = merged_atpdatafinal.sort_values(by=['P1', 'Date'], ascending=[True, True])\n",
        "\n",
        "\n",
        "# Compter le nombre d'occurrences de chaque joueur dans la colonne 'P1'\n",
        "counts = merged_atpdatafinal['P1'].value_counts()\n",
        "\n",
        "# Sélectionner les joueurs qui apparaissent au moins 10 fois\n",
        "selected_players = counts[counts >= 10].index\n",
        "\n",
        "# Filtrer le DataFrame pour inclure uniquement les joueurs sélectionnés\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal[merged_atpdatafinal['P1'].isin(selected_players)]\n",
        "\n",
        "\n",
        "# Liste des colonnes pour lesquelles vous voulez calculer la moyenne mobile\n",
        "colonnes_moyenne = ['P1_rank', 'P1_rank_pts', 'P2_rank', 'P2_rank_pts', 'P1_ace', 'P1_df', 'P1_svpt', 'P2_svpt',\n",
        "                    'P1_1stIn', 'P1_1stWon', 'P1_2ndWon', 'P1_SvGms', 'P1_bpSaved', 'P1_bpFaced', 'P2_ace', 'P2_df',\n",
        "                    'P2_svpt', 'P2_1stIn', 'P2_1stWon', 'P2_2ndWon', 'P2_SvGms', 'P2_bpSaved', 'P2_bpFaced']\n",
        "\n",
        "# Grouper par 'P1' et 'surface', puis calculer la moyenne mobile sur les 5 matchs précédents pour chaque colonne\n",
        "for col in colonnes_moyenne:\n",
        "    merged_atpdatafinal_filtered[f'{col}_moy'] = merged_atpdatafinal_filtered.groupby('P1')[col].rolling(window=5, min_periods=1).mean().reset_index(level=0, drop=True)\n",
        "\n",
        "\n",
        "# Trier à nouveau le DataFrame par ordre croissant de la colonne 'Date'\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal_filtered.sort_values(by='Date')\n",
        "\n",
        "# Réinitialiser l'index si nécessaire\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal_filtered.reset_index(drop=True)\n",
        "\n",
        "\n",
        "merged_atpdatafinal_filtered['Year'] = merged_atpdatafinal_filtered['Date'].dt.year\n",
        "merged_atpdatafinal_filtered['Month'] = merged_atpdatafinal_filtered['Date'].dt.month\n",
        "merged_atpdatafinal_filtered['Day'] = merged_atpdatafinal_filtered['Date'].dt.day\n",
        "\n",
        "# Supprimer la colonne Date si elle n'est plus nécessaire\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal_filtered.drop(columns=['Date'])\n",
        "\n",
        "\n",
        "colonnes_a_supprimer = ['P1_rank', 'P1_rank_pts', 'P2_rank', 'P2_rank_pts', 'P1_ace', 'P1_df', 'P1_svpt', 'P2_svpt',\n",
        "                        'P1_1stIn', 'P1_1stWon', 'P1_2ndWon', 'P1_SvGms', 'P1_bpSaved', 'P1_bpFaced', 'P2_ace', 'P2_df',\n",
        "                        'P2_svpt', 'P2_1stIn', 'P2_1stWon', 'P2_2ndWon', 'P2_SvGms', 'P2_bpSaved', 'P2_bpFaced']\n",
        "\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal_filtered.drop(columns=colonnes_a_supprimer)\n",
        "\n",
        "\n",
        "# Repérer les colonnes catégorielles\n",
        "colonnes_categorielles = merged_atpdatafinal_filtered.select_dtypes(include=['object']).columns\n",
        "print(colonnes_categorielles)\n",
        "\n",
        "\n",
        "merged_atpdatafinal_filtered['result'] = merged_atpdatafinal_filtered['result'].astype(float)\n",
        "\n",
        "merged_atpdatafinal_filtered = merged_atpdatafinal_filtered[merged_atpdatafinal_filtered['P2_hand'] != 'U']\n",
        "\n",
        "\n",
        "def filter_by_player(df, player_name):\n",
        "    return df[(df['P1'] == player_name) | (df['P2'] == player_name)]\n",
        "\n",
        "\n",
        "# Utilisation de la fonction avec le nom du joueur\n",
        "player_name = 'Marco Cecchinato'\n",
        "filtered_atpdf = filter_by_player(merged_atpdatafinal_filtered, player_name)\n",
        "\n",
        "\n",
        "# Colonnes catégorielles\n",
        "cat = ['tourney_name', 'surface', 'tourney_level', 'P1', 'P1_hand', 'P1_ioc',\n",
        "       'P2', 'P2_hand', 'P2_ioc', 'round']\n",
        "\n",
        "# Utiliser get_dummies pour encoder ces colonnes\n",
        "filtered_atpdf_encoded = pd.get_dummies(filtered_atpdf, columns=cat)\n",
        "\n",
        "\n",
        "#Séparation des données explicatives de la variable cible\n",
        "\n",
        "feats = filtered_atpdf_encoded.drop('result', axis=1)\n",
        "target = filtered_atpdf_encoded['result']\n",
        "\n",
        "\n",
        "variables_num = feats.select_dtypes(include=['int', 'float','datetime64'])\n",
        "\n",
        "\n",
        "\n",
        "#Séparation du jeu de données en un jeu d'entrainement et de test en spécifiant la répartition temporelle\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    feats, target,\n",
        "    test_size=0.15,\n",
        "    random_state=42,\n",
        "    shuffle=False)\n",
        "\n",
        "#Standardiser les valeurs numériques à l'aide de StandardScaler\n",
        "\n",
        "sc = StandardScaler()\n",
        "variables_num_list = variables_num.columns.tolist()\n",
        "X_train[variables_num_list] = sc.fit_transform(X_train[variables_num_list])\n",
        "X_test[variables_num_list] = sc.transform(X_test[variables_num_list])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "k = 5  # Choisissez un nombre k\n",
        "model = KNeighborsClassifier(n_neighbors=k)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "#On observe\n",
        "print(\"le score à l'entrainement est\", model.score(X_train,y_train))\n",
        "print(\"le score au test est\", model.score(X_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rszaasbnw14n",
        "outputId": "da4d3dd0-e8b9-4aad-d37f-5554787e6655"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "le score à l'entrainement est 0.6986301369863014\n",
            "le score au test est 0.5384615384615384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rapport de résultats de prédiction\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "display(pd.crosstab(y_test,y_pred, rownames=['Realité'], colnames=['Prédiction']))\n",
        "\n",
        "\n",
        "print(classification_report(y_test, y_pred, ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "hXQhbglhDaKD",
        "outputId": "23871a47-7c18-4a84-d46f-1bd9180d23cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Prédiction  -1.0   1.0\n",
              "Realité               \n",
              "-1.0           4     3\n",
              " 1.0           3     3"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b16ad50c-baf4-42f3-8cac-ea05727eed39\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Prédiction</th>\n",
              "      <th>-1.0</th>\n",
              "      <th>1.0</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Realité</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>-1.0</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1.0</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b16ad50c-baf4-42f3-8cac-ea05727eed39')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b16ad50c-baf4-42f3-8cac-ea05727eed39 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b16ad50c-baf4-42f3-8cac-ea05727eed39');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-17be3a56-3099-4c81-ae48-8466488c170b\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-17be3a56-3099-4c81-ae48-8466488c170b')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-17be3a56-3099-4c81-ae48-8466488c170b button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        -1.0       0.57      0.57      0.57         7\n",
            "         1.0       0.50      0.50      0.50         6\n",
            "\n",
            "    accuracy                           0.54        13\n",
            "   macro avg       0.54      0.54      0.54        13\n",
            "weighted avg       0.54      0.54      0.54        13\n",
            "\n"
          ]
        }
      ]
    }
  ]
}