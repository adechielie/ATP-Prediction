"""
Script principal pour le pipeline complet ATP Prediction.
"""
import argparse
from pathlib import Path

from src.data.atp_collector import ATPDataCollector
from src.data.climate_collector import ClimateDataCollector
from src.data.preprocessor import ATPDataPreprocessor
from src.features.feature_engineer import ATPFeatureEngineer
from src.utils.logger import logger, setup_logging


def main(
    force_download: bool = False,
    save_bronze: bool = True,
    save_silver: bool = True,
    save_gold: bool = True
):
    """
    Pipeline complet de pr√©paration des donn√©es.
    
    Args:
        force_download: Forcer le t√©l√©chargement des donn√©es
        save_bronze: Sauvegarder les donn√©es bronze
        save_silver: Sauvegarder les donn√©es silver
        save_gold: Sauvegarder les donn√©es gold
    """
    logger.info("=" * 80)
    logger.info("üöÄ ATP PREDICTION - PIPELINE D√âMARR√â")
    logger.info("=" * 80)
    
    # ==========================================
    # √âTAPE 1 : COLLECTE DES DONN√âES (BRONZE)
    # ==========================================
    logger.info("\nüì• √âTAPE 1/4 : Collecte des donn√©es ATP...")
    
    atp_collector = ATPDataCollector()
    atp_data = atp_collector.get_or_fetch_data(force_download=force_download)
    
    logger.info(f"‚úÖ Donn√©es ATP charg√©es : {len(atp_data):,} matchs")
    
    # Donn√©es climatiques
    logger.info("\nüå§Ô∏è  Collecte des donn√©es climatiques...")
    climate_collector = ClimateDataCollector()
    climate_data = climate_collector.get_or_fetch_data(force_download=force_download)
    
    logger.info(f"‚úÖ Donn√©es climatiques charg√©es : {len(climate_data):,} enregistrements")
    
    # Sauvegarder bronze
    if save_bronze:
        bronze_path = Path(__file__).parent / "data" / "bronze"
        bronze_path.mkdir(parents=True, exist_ok=True)
        
        atp_data.to_csv(bronze_path / "atp_matches_bronze.csv", index=False)
        climate_data.to_csv(bronze_path / "climate_bronze.csv", index=False)
        logger.info(f"üíæ Donn√©es bronze sauvegard√©es dans {bronze_path}")
    
    # ==========================================
    # √âTAPE 2 : PREPROCESSING (SILVER)
    # ==========================================
    logger.info("\nüßπ √âTAPE 2/4 : Preprocessing des donn√©es...")
    
    preprocessor = ATPDataPreprocessor()
    clean_data = preprocessor.preprocess(atp_data, augment_data=True)
    
    # Fusionner avec les donn√©es climatiques
    logger.info("\nüîó Fusion avec les donn√©es climatiques...")
    clean_data = clean_data.merge(
        climate_data,
        left_on=['Location', 'tourney_date'],
        right_on=['city', 'date'],
        how='left'
    )
    clean_data = clean_data.drop(columns=['city', 'date'], errors='ignore')
    
    logger.info(f"‚úÖ Donn√©es nettoy√©es : {len(clean_data):,} matchs")
    
    # Sauvegarder silver
    if save_silver:
        silver_path = Path(__file__).parent / "data" / "silver"
        silver_path.mkdir(parents=True, exist_ok=True)
        
        clean_data.to_csv(silver_path / "atp_matches_silver.csv", index=False)
        logger.info(f"üíæ Donn√©es silver sauvegard√©es dans {silver_path}")
    
    # ==========================================
    # √âTAPE 3 : FEATURE ENGINEERING (GOLD)
    # ==========================================
    logger.info("\n‚öôÔ∏è  √âTAPE 3/4 : Feature engineering...")
    
    engineer = ATPFeatureEngineer()
    features_data = engineer.engineer_features(clean_data)
    
    logger.info(f"‚úÖ Features cr√©√©es : {len(features_data.columns)} colonnes")
    
    # Sauvegarder gold
    if save_gold:
        gold_path = Path(__file__).parent / "data" / "gold"
        gold_path.mkdir(parents=True, exist_ok=True)
        
        features_data.to_csv(gold_path / "atp_matches_gold.csv", index=False)
        logger.info(f"üíæ Donn√©es gold sauvegard√©es dans {gold_path}")
    
    # ==========================================
    # √âTAPE 4 : R√âSUM√â
    # ==========================================
    logger.info("\n" + "=" * 80)
    logger.info("üìä R√âSUM√â DU PIPELINE")
    logger.info("=" * 80)
    logger.info(f"Bronze : {len(atp_data):,} matchs bruts")
    logger.info(f"Silver : {len(clean_data):,} matchs nettoy√©s")
    logger.info(f"Gold   : {len(features_data):,} matchs avec {len(features_data.columns)} features")
    logger.info("=" * 80)
    logger.info("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS")
    logger.info("=" * 80)
    
    return features_data


if __name__ == "__main__":
    # Configurer le logging
    setup_logging(log_level="INFO")
    
    # Parser les arguments
    parser = argparse.ArgumentParser(
        description="Pipeline ATP Prediction"
    )
    parser.add_argument(
        "--force-download",
        action="store_true",
        help="Forcer le t√©l√©chargement des donn√©es"
    )
    parser.add_argument(
        "--no-save",
        action="store_true",
        help="Ne pas sauvegarder les fichiers interm√©diaires"
    )
    
    args = parser.parse_args()
    
    # Ex√©cuter le pipeline
    try:
        main(
            force_download=args.force_download,
            save_bronze=not args.no_save,
            save_silver=not args.no_save,
            save_gold=not args.no_save
        )
    except Exception as e:
        logger.exception(f"‚ùå Erreur fatale : {e}")
        raise
