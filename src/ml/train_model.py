"""
Script d'entra√Ænement du mod√®le ATP.

Sauvegarde le mod√®le avec la date du jour: model_YYYYMMDD.pkl
Si un mod√®le existe d√©j√† pour ce jour, il est √©cras√©.

Usage:
    python -m src.ml.train_model
"""
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib
from loguru import logger
from pathlib import Path
from datetime import datetime

from ..utils.config import config


def train_model():
    """Fonction principale d'entra√Ænement."""
    
    logger.info("=" * 70)
    logger.info("üéæ ENTRA√éNEMENT DU MOD√àLE ATP")
    logger.info("=" * 70)
    
    # === CHARGEMENT DES DONN√âES ===
    logger.info("üîµ Loading GOLD dataset...")
    gold_path = config.data_paths["gold"] / "atp_matches_gold.csv"
    
    if not gold_path.exists():
        raise FileNotFoundError(f"‚ùå Dataset GOLD non trouv√©: {gold_path}")
    
    df = pd.read_csv(gold_path)
    logger.info(f"Dataset loaded: {df.shape}")

    # === IDENTIFIER LA COLONNE TARGET ===
    if "result" in df.columns:
        target_col = "result"
    elif "winner" in df.columns:
        target_col = "winner"
    else:
        raise ValueError(f"‚ùå No target column found. Available columns: {df.columns.tolist()}")
    
    logger.info(f"üìä Using target column: '{target_col}'")

    # === PR√âPARATION FEATURES / TARGET ===
    y = df[target_col]
    X = df.drop(target_col, axis=1)
    
    # Enlever les colonnes non-num√©riques
    non_numeric_cols = X.select_dtypes(exclude=['number']).columns.tolist()
    if non_numeric_cols:
        logger.warning(f"‚ö†Ô∏è Dropping non-numeric columns: {non_numeric_cols}")
        X = X.select_dtypes(include=['number'])
    
    # G√©rer les valeurs manquantes
    if X.isnull().any().any():
        logger.warning("‚ö†Ô∏è Missing values detected. Filling with 0...")
        X = X.fillna(0)
    
    logger.info(f"‚úÖ Features shape: {X.shape}")
    logger.info(f"‚úÖ Target distribution:\n{y.value_counts()}")

    # === TRAIN / TEST SPLIT ===
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=config.model_config["test_size"], random_state=42
    )
    
    logger.info(f"Train set: {X_train.shape}, Test set: {X_test.shape}")

    # === CONFIGURATION DU MOD√àLE ===
    algo = config.model_config["algorithm"]
    params = config.model_config["hyperparameters"][algo]

    logger.info(f"üîß Training model: {algo}")
    logger.info(f"Hyperparameters: {params}")

    # === S√âLECTION DU MOD√àLE ===
    if algo == "gradient_boosting":
        from sklearn.ensemble import GradientBoostingClassifier
        model = GradientBoostingClassifier(**params)

    elif algo == "random_forest":
        from sklearn.ensemble import RandomForestClassifier
        model = RandomForestClassifier(**params)

    elif algo == "logistic_regression":
        from sklearn.linear_model import LogisticRegression
        model = LogisticRegression(**params)

    elif algo == "knn":
        from sklearn.neighbors import KNeighborsClassifier
        model = KNeighborsClassifier(**params)

    else:
        raise ValueError(f"Unknown algorithm: {algo}")

    # === ENTRA√éNEMENT ===
    logger.info("üöÄ Training started...")
    start_time = datetime.now()
    
    model.fit(X_train, y_train)
    
    training_time = (datetime.now() - start_time).total_seconds()
    logger.success(f"‚úÖ Training completed in {training_time:.1f}s")

    # === √âVALUATION ===
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)

    logger.success(f"üéØ Model accuracy: {acc:.2%}")

    # === SAUVEGARDE AVEC DATE DU JOUR ===
    models_dir = config.data_paths["models"]
    models_dir.mkdir(parents=True, exist_ok=True)
    
    # Nom avec la date du jour: model_YYYYMMDD.pkl
    date_str = datetime.now().strftime("%Y%m%d")
    model_filename = f"model_{date_str}.pkl"
    model_path = models_dir / model_filename
    
    # Si un mod√®le du jour existe d√©j√†, l'√©craser
    if model_path.exists():
        logger.warning(f"‚ö†Ô∏è  Mod√®le du jour existe d√©j√†, √©crasement: {model_filename}")
    
    joblib.dump(model, model_path)
    
    size_mb = model_path.stat().st_size / (1024 * 1024)
    logger.success(f"üíæ Model saved: {model_filename} ({size_mb:.2f} MB)")
    
    # === R√âSUM√â ===
    logger.info("=" * 70)
    logger.success("‚úÖ ENTRA√éNEMENT TERMIN√â AVEC SUCC√àS")
    logger.info(f"üìä Accuracy: {acc:.2%}")
    logger.info(f"üìÅ Mod√®le: {model_path}")
    logger.info(f"‚è±Ô∏è  Dur√©e: {training_time:.1f}s")
    logger.info("=" * 70)
    
    return model, acc


if __name__ == "__main__":
    train_model()