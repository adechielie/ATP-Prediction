# ğŸ¾ ATP Match Prediction - Architecture Professionnelle

## ğŸ“‹ Vue d'ensemble

SystÃ¨me de prÃ©diction des rÃ©sultats de matchs de tennis ATP utilisant le Machine Learning.

**Architecture modulaire** avec sÃ©paration claire des responsabilitÃ©s, pipeline de donnÃ©es bronze/silver/gold, et dÃ©ploiement vers Microsoft Fabric ou Databricks.

---

## ğŸ—ï¸ Architecture

```
atp-prediction-refactor/
â”œâ”€â”€ config.yaml                 # Configuration centralisÃ©e
â”œâ”€â”€ requirements.txt            # DÃ©pendances Python
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                   # Collecte et preprocessing
â”‚   â”‚   â”œâ”€â”€ atp_collector.py       # TÃ©lÃ©chargement donnÃ©es ATP
â”‚   â”‚   â”œâ”€â”€ climate_collector.py   # TÃ©lÃ©chargement donnÃ©es mÃ©tÃ©o
â”‚   â”‚   â””â”€â”€ preprocessor.py        # Nettoyage des donnÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ features/               # Feature engineering
â”‚   â”‚   â””â”€â”€ feature_engineer.py    # CrÃ©ation features avancÃ©es
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                 # ModÃ¨les ML
â”‚   â”‚   â”œâ”€â”€ trainer.py             # EntraÃ®nement modÃ¨les
â”‚   â”‚   â””â”€â”€ predictor.py           # PrÃ©dictions
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                    # API FastAPI
â”‚   â”‚   â”œâ”€â”€ main.py                # Point d'entrÃ©e API
â”‚   â”‚   â””â”€â”€ routes.py              # Routes API
â”‚   â”‚
â”‚   â””â”€â”€ utils/                  # Utilitaires
â”‚       â”œâ”€â”€ config.py              # Gestion configuration
â”‚       â””â”€â”€ logger.py              # Logging
â”‚
â”œâ”€â”€ data/                       # Pipeline de donnÃ©es
â”‚   â”œâ”€â”€ raw/                       # DonnÃ©es brutes
â”‚   â”œâ”€â”€ bronze/                    # DonnÃ©es ingÃ©rÃ©es
â”‚   â”œâ”€â”€ silver/                    # DonnÃ©es nettoyÃ©es
â”‚   â””â”€â”€ gold/                      # Features pour ML
â”‚
â”œâ”€â”€ models/                     # ModÃ¨les entraÃ®nÃ©s
â”œâ”€â”€ logs/                       # Fichiers de logs
â”œâ”€â”€ notebooks/                  # Notebooks Jupyter
â”œâ”€â”€ tests/                      # Tests unitaires
â””â”€â”€ scripts/                    # Scripts utilitaires
    â”œâ”€â”€ train_model.py
    â”œâ”€â”€ run_pipeline.py
    â””â”€â”€ deploy_to_fabric.py
```

---

## ğŸš€ DÃ©marrage rapide

### 1. Installation

```bash
# Cloner le repo
git clone https://github.com/adechielie/ATP-Prediction.git
cd ATP-Prediction

# CrÃ©er environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les dÃ©pendances
pip install -r requirements.txt
```

### 2. Configuration

Modifier `config.yaml` selon vos besoins :

```yaml
data:
  sources:
    atp_github:
      years_range: [2000, 2025]
  
model:
  algorithm: "gradient_boosting"
  test_size: 0.15
```

### 3. Collecte des donnÃ©es

```python
from src.data.atp_collector import ATPDataCollector
from src.data.climate_collector import ClimateDataCollector

# TÃ©lÃ©charger donnÃ©es ATP
atp_collector = ATPDataCollector()
atp_data = atp_collector.collect_all_years()

# TÃ©lÃ©charger donnÃ©es climatiques
climate_collector = ClimateDataCollector()
climate_data = climate_collector.collect_climate_data()
```

### 4. Preprocessing et Feature Engineering

```python
from src.data.preprocessor import ATPDataPreprocessor
from src.features.feature_engineer import ATPFeatureEngineer

# Preprocessing
preprocessor = ATPDataPreprocessor()
clean_data = preprocessor.preprocess(atp_data)

# Feature engineering
engineer = ATPFeatureEngineer()
features = engineer.engineer_features(clean_data)
```

---

## ğŸ“Š Pipeline de donnÃ©es (Medallion Architecture)

### Bronze Layer (Raw)
- DonnÃ©es brutes tÃ©lÃ©chargÃ©es depuis les sources
- Aucune transformation
- Format CSV original

### Silver Layer (Cleaned)
- DonnÃ©es nettoyÃ©es et normalisÃ©es
- Suppression des valeurs manquantes
- Standardisation des colonnes
- Filtrage des tournois

### Gold Layer (Features)
- Features ML prÃªtes Ã  l'emploi
- ELO ratings
- Head-to-head statistics
- Surface performance metrics
- Moyennes glissantes

---

## ğŸ¤– StratÃ©gie de modÃ©lisation

### âŒ Approche rejetÃ©e : Un modÃ¨le par joueur

**ProblÃ¨mes identifiÃ©s :**
- âŒ Cold start pour nouveaux joueurs
- âŒ Maintenance complexe (1000+ modÃ¨les)
- âŒ DonnÃ©es insuffisantes pour certains joueurs
- âŒ Impossible Ã  scaler

### âœ… Approche recommandÃ©e : ModÃ¨le unique unifiÃ©

**Avantages :**
- âœ… Features par joueur (ELO, stats, H2H)
- âœ… GÃ©nÃ©ralise bien aux nouveaux joueurs
- âœ… Un seul modÃ¨le Ã  maintenir
- âœ… Scalable et production-ready
- âœ… Approche standard dans l'industrie

**Features clÃ©s :**
- ELO rating dynamique
- Head-to-head history
- Performance par surface
- Moyennes glissantes (5 derniers matchs)
- Statistiques de service
- MÃ©tÃ©o (tempÃ©rature, vent)

---

## ğŸ”§ Algorithmes disponibles

Configuration dans `config.yaml` :

```yaml
model:
  algorithm: "gradient_boosting"  # Choix recommandÃ©
  
  # Options disponibles:
  # - gradient_boosting (XGBoost/LightGBM)
  # - random_forest
  # - logistic_regression
  # - knn
```

**Performances attendues** (sur validation set) :
- GradientBoosting: ~70-75% accuracy
- RandomForest: ~68-72% accuracy
- LogisticRegression: ~65-70% accuracy
- KNN: ~60-65% accuracy

---

## ğŸ“ˆ Utilisation pour todoba.net

### 1. Page Streamlit

CrÃ©er `app_streamlit.py` :

```python
import streamlit as st
import pandas as pd
from src.models.predictor import ATPPredictor

st.title("ğŸ¾ ATP Match Prediction")

# SÃ©lection joueurs
players = predictor.get_all_players()
player1 = st.selectbox("Joueur 1", players)
player2 = st.selectbox("Joueur 2", players)

# PrÃ©diction
if st.button("PrÃ©dire"):
    odds = predictor.predict_match_odds(player1, player2)
    
    st.metric("ProbabilitÃ© victoire " + player1, f"{odds['player1']:.1%}")
    st.metric("ProbabilitÃ© victoire " + player2, f"{odds['player2']:.1%}")
    
    # Statistiques rÃ©centes
    st.subheader("ğŸ“Š Statistiques rÃ©centes")
    stats = predictor.get_player_recent_stats(player1)
    
    col1, col2, col3 = st.columns(3)
    col1.metric("ELO", f"{stats['elo']:.0f}")
    col2.metric("Win Rate (5 derniers)", f"{stats['win_rate']:.1%}")
    col3.metric("Aces moyens", f"{stats['avg_aces']:.1f}")
```

### 2. Lancer Streamlit

```bash
streamlit run app_streamlit.py --server.port 8501
```

---

## ğŸ”„ Pipeline d'automatisation

### Configuration Kafka (optionnel)

```yaml
pipeline:
  kafka:
    enabled: true
    bootstrap_servers: "localhost:9092"
    topic: "atp-matches-raw"
```

### Configuration Microsoft Fabric

```yaml
pipeline:
  fabric:
    enabled: true
    workspace: "atp-prediction"
    lakehouse: "atp-data"
  
  schedule:
    ingestion: "daily"      # Nouvelles donnÃ©es chaque jour
    training: "weekly"      # RÃ©entraÃ®nement hebdomadaire
```

### Script de dÃ©ploiement

```python
# scripts/deploy_to_fabric.py
from src.pipeline.fabric_deployer import FabricDeployer

deployer = FabricDeployer()
deployer.deploy_pipeline()
deployer.schedule_jobs()
```

---

## ğŸ“… Workflow complet

```mermaid
graph LR
    A[Sources externes] --> B[Kafka/Ingestion]
    B --> C[Bronze Layer]
    C --> D[Silver Layer]
    D --> E[Gold Layer]
    E --> F[ML Model]
    F --> G[API REST]
    G --> H[Frontend Streamlit]
```

**Automatisation :**
1. **Daily** : Ingestion nouvelles donnÃ©es de matchs
2. **Weekly** : RÃ©entraÃ®nement du modÃ¨le avec nouvelles donnÃ©es
3. **Real-time** : API disponible 24/7 pour prÃ©dictions

---

## ğŸ§ª Tests

```bash
# Lancer tous les tests
pytest tests/

# Avec couverture
pytest --cov=src tests/

# Tests spÃ©cifiques
pytest tests/test_preprocessor.py
```

---

## ğŸ“¦ DÃ©ploiement

### Fabric / Databricks

```bash
# DÃ©ployer vers Fabric
python scripts/deploy_to_fabric.py

# DÃ©ployer vers Databricks
python scripts/deploy_to_databricks.py
```

### API REST

```bash
# Lancer API en local
uvicorn src.api.main:app --reload --port 8000

# Production avec Gunicorn
gunicorn src.api.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

---

## ğŸ“ Bonnes pratiques du code

âœ… **Ce qui a Ã©tÃ© amÃ©liorÃ©** :

1. **SÃ©paration des responsabilitÃ©s** : Chaque module a une fonction claire
2. **Configuration externalisÃ©e** : Un seul fichier YAML
3. **Logging structurÃ©** : Traces claires avec loguru
4. **Type hints** : Meilleure lisibilitÃ© et autocomplÃ©tion
5. **Docstrings** : Documentation pour chaque fonction
6. **Gestion d'erreurs** : Try/except appropriÃ©s
7. **Tests unitaires** : Code testable et maintenable
8. **DRY** : Pas de code rÃ©pÃ©titif
9. **PEP 8** : Conventions Python respectÃ©es

âŒ **ProblÃ¨mes de l'ancien code corrigÃ©s** :

- Code monolithique dans notebooks
- Variables en dur
- Pas de logging
- Boucles inefficaces
- SettingWithCopyWarning pandas
- Pas de tests
- Pas de modularitÃ©

---

## ğŸ¤ Contribution

```bash
# Formatter le code
black src/

# Linter
flake8 src/

# Type checking
mypy src/
```

---

## ğŸ“„ Licence

MIT

---

## ğŸ‘¨â€ğŸ’» Auteur

**adechielie**
- GitHub: [@adechielie](https://github.com/adechielie)
- Website: [todoba.net](https://todoba.net)
